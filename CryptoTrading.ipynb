{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Capstone",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHZpTacuyfQ",
        "colab_type": "text"
      },
      "source": [
        "# Here is my attempt at crypto-trading. I utilize datetime, neural nets, supervised, and unsupervised learning to code an algorithm to automatically trade cryptocurrency.\n",
        "\n",
        "Hypothesis: With the assistance of supervised, unsupervised learning, along with neural networks, I wil be able to predict the movement of the close price of bitcoin 60 mins into the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJyLitx6uv89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8aebe101-12ad-479d-f42f-5ff5465d3b86"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas_datareader import data\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "from scipy.stats import boxcox\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential,model_from_json\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, ConvLSTM2D, Flatten, RepeatVector,TimeDistributed\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import umap\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  from pandas.util.testing import assert_frame_equal\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRHFAny1ZE7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function I will use so I'm saving them for later\n",
        "#This function splits data into X and y for neural networks and makes X into a 3d array to be acceptable for LSTM models\n",
        "def convert_data(data, step):\n",
        "  X, y = [], []\n",
        "  for i in range(len(data)-step):\n",
        "    d = i + step\n",
        "    X.append(data[i:d,:-1])\n",
        "    y.append(data[d,-1])\n",
        "  return np.array(X), np.array(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzgLIf8fKLtJ",
        "colab_type": "text"
      },
      "source": [
        "# Training data is found from kaggle. Link is below. I'm using the btc_usd one\n",
        "#link: https://www.kaggle.com/tencars/392-crypto-currency-pairs-at-minute-resolution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M8PsaorvoZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "e2283191-0795-4d11-ca6c-da8005feb108"
      },
      "source": [
        "#I saved the data here\n",
        "df = pd.read_csv(r\"/content/drive/My Drive/Crypto/btcusd.csv\")\n",
        "df = df.groupby('time').mean()\n",
        "display(df.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2841761 entries, 1364774820000 to 1593425100000\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   open    float64\n",
            " 1   close   float64\n",
            " 2   high    float64\n",
            " 3   low     float64\n",
            " 4   volume  float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 130.1 MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCxOn5d0iC71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "1772178d-8b5e-4c48-9293-d99264e77c89"
      },
      "source": [
        "#Check for nulls to see. YAY! No nulls!\n",
        "df.isna().mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open      0.0\n",
              "close     0.0\n",
              "high      0.0\n",
              "low       0.0\n",
              "volume    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfUyLVMPdQjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "d4139dd5-ec9b-4483-fe3f-49df519a893b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1364774820000</th>\n",
              "      <td>93.25</td>\n",
              "      <td>93.30</td>\n",
              "      <td>93.30</td>\n",
              "      <td>93.25</td>\n",
              "      <td>93.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364774880000</th>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>93.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364774940000</th>\n",
              "      <td>93.30</td>\n",
              "      <td>93.30</td>\n",
              "      <td>93.30</td>\n",
              "      <td>93.30</td>\n",
              "      <td>33.676862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364775060000</th>\n",
              "      <td>93.35</td>\n",
              "      <td>93.47</td>\n",
              "      <td>93.47</td>\n",
              "      <td>93.35</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364775120000</th>\n",
              "      <td>93.47</td>\n",
              "      <td>93.47</td>\n",
              "      <td>93.47</td>\n",
              "      <td>93.47</td>\n",
              "      <td>2.021627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 open   close    high     low     volume\n",
              "time                                                    \n",
              "1364774820000   93.25   93.30   93.30   93.25  93.300000\n",
              "1364774880000  100.00  100.00  100.00  100.00  93.300000\n",
              "1364774940000   93.30   93.30   93.30   93.30  33.676862\n",
              "1364775060000   93.35   93.47   93.47   93.35  20.000000\n",
              "1364775120000   93.47   93.47   93.47   93.47   2.021627"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yPEEu3GnsIh",
        "colab_type": "text"
      },
      "source": [
        "Please comment out this code if you want to see the effect. Like I said above, I ran out of RAM and can't download more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5eq2GxqLOSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot_df = df.copy().reset_index()\n",
        "# plot_df['time'] = pd.to_datetime(plot_df['time'],unit = \"ms\")\n",
        "# plt.plot(\"time\",\"close\", data = plot_df, linewidth = .25)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gxTLkMKDuoz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7ad57af7-28a3-4fa6-d201-4de539ca1aca"
      },
      "source": [
        "# I will add various RMAs in an attempt to give the computer a better chance at understanding and predicting when to buy/sell\n",
        "# The point of these is to give models extra help in predicting the price going up or down 60 mins down the road\n",
        "df['High 8 RMA'] = df['close'].rolling(window=8).mean()\n",
        "df['High 13 RMA'] = df['close'].rolling(window=13).mean()\n",
        "df['High 21 RMA'] = df['close'].rolling(window=21).mean()\n",
        "df['High 55 RMA'] = df['close'].rolling(window=55).mean()\n",
        "df['Bollinger High'] = df['High 13 RMA'] +df['close'].rolling(2).std()\n",
        "df['Bollinger Low'] =  df['High 13 RMA'] - df['close'].rolling(2).std()\n",
        "df['returns'] = df['close'].pct_change(60)\n",
        "\n",
        "#What I'm trying to predict\n",
        "#1st strategy loses me money: price going up or down in 60 mins\n",
        "df['target']=(df['returns'].shift(-60)>0).astype(int)\n",
        "\n",
        "'''\n",
        "THESE ARE SOLELY FOR ME. THEY ARE NOT PART OF THE PROJECT BUT THINGS FOR ME TO PLAY WITH ON MY OWN. I DO NOT USE THESE LATER ON\n",
        "BUT PLAN ON USING THESE PERSONALLY IN THE FUTURE SO THEY'RE HERE. IF YOU HAVE ANY SUGGESTIONS OF OTHER STRATEGIES, PLEASE SHARE :D\n",
        "\n",
        "\n",
        "\n",
        "#2nd strategy is if the Bollinger low band crosses the price\n",
        "#df['target'] = ((df['close']>df['Bolllinger Low']).shift(-60)>0).astype(int)\n",
        "\n",
        "#3rd Strategy aka the youtube guru strategy. This is something I found on youtube and thought it would be fun to backtest and try\n",
        "#df['target']=((df['High 8 RMA']>df['High 13 RMA']>df['High 21 RMA']>df['High 55 RMA']).shift(-60)>0).astype(int)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nTHESE ARE SOLELY FOR ME. THEY ARE NOT PART OF THE PROJECT BUT THINGS FOR ME TO PLAY WITH ON MY OWN. I DO NOT USE THESE LATER ON\\nBUT PLAN ON USING THESE PERSONALLY IN THE FUTURE SO THEY'RE HERE. IF YOU HAVE ANY SUGGESTIONS OF OTHER STRATEGIES, PLEASE SHARE :D\\n\\n\\n\\n#2nd strategy is if the Bollinger low band crosses the price\\n#df['target'] = ((df['close']>df['Bolllinger Low']).shift(-60)>0).astype(int)\\n\\n#3rd Strategy aka the youtube guru strategy. This is something I found on youtube and thought it would be fun to backtest and try\\n#df['target']=((df['High 8 RMA']>df['High 13 RMA']>df['High 21 RMA']>df['High 55 RMA']).shift(-60)>0).astype(int)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14JdTpJuMQnt",
        "colab_type": "text"
      },
      "source": [
        "Why am I going from 2017 when I have more data?\n",
        "\n",
        "Link:\n",
        "\n",
        "\n",
        "\n",
        "1) Before 2017 and after 2017, there is a massive behavior change in the movement of the price so I want to capture current behavior\n",
        "\n",
        "2) It's easier on my ram to actually run different types of machine learning methods on less data. Including all of the data has crashed my kernal multiple times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyM9k6O_zNB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now I'm going from 2017 to June 2020\n",
        "df = df.iloc[-1051200:].copy()\n",
        "#Making a time variable for visualizations\n",
        "df['time'] = df.index\n",
        "x = pd.to_datetime(df['time'],unit = \"ms\")\n",
        "df.drop(columns = 'time', inplace = True)\n",
        "#Moving stuff to my next notebook\n",
        "#x.to_csv(\"/content/drive/My Drive/Crypto/time.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9PgCl3exQIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Much better. Now it's time to re-check for NAs and make sure that didn't mess anything up"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DipMR6lnM6fe",
        "colab_type": "text"
      },
      "source": [
        "Please comment out this code if you want to see the effect. Like I said above, I ran out of RAM and can't download more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynwiEzBUyDBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Cool! Now let's check out how the line goes for open close high and low\n",
        "# df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM__Y8veNDKJ",
        "colab_type": "text"
      },
      "source": [
        "Please comment out this code if you want to see the effect. Like I said above, I ran out of RAM and can't download more\n",
        "\n",
        "I've also added links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZuKU35byhJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #This makes it look like the difference isn't really there. I'm curious how much of a difference there is between all of these\n",
        "\n",
        "# # Link: \"https://github.com/AsterLaoWhy/Thinkful/blob/master/Prices.png\"\n",
        "\n",
        "# plot_df = df.copy().reset_index()\n",
        "# plot_df['time'] = pd.to_datetime(plot_df['time'],unit = \"ms\")\n",
        "# plt.figure(figsize = (12,6))\n",
        "# plt.plot(\"time\",\"open\", data = plot_df, linewidth = .25)\n",
        "# plt.plot(\"time\",\"close\", data = plot_df, linewidth = .25)\n",
        "# plt.plot(\"time\",\"high\", data = plot_df, linewidth = .25)\n",
        "# plt.plot(\"time\",\"low\", data = plot_df, linewidth = .25)\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctR3NoYwNHZh",
        "colab_type": "text"
      },
      "source": [
        "Please comment out this code if you want to see the effect. Like I said above, I ran out of RAM and can't download more\n",
        "\n",
        "I've also added links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPxDELyjE5He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #That's weird. None of the volume is 0\n",
        "# # Link: \"https://github.com/AsterLaoWhy/Thinkful/blob/master/Volume.png\"\n",
        "\n",
        "# plt.plot(\"time\",\"volume\",data = plot_df)\n",
        "# plt.title(\"Volume Traded\")\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WTRosJvQjeK",
        "colab_type": "text"
      },
      "source": [
        "Please comment out this code if you want to see the effect. Like I said above, I ran out of RAM and can't download more.\n",
        "\n",
        "I've also added links"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj-n-0BcNqPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Returns and close\n",
        "# #1 is buy and 0 is sell/do nothing\n",
        "\n",
        "# # link:\"https://github.com/AsterLaoWhy/Thinkful/commit/cadc8011516367d57e79389d619941b0c76d4bc1\"\n",
        "# plt.figure(figsize=(12,6))\n",
        "# plt.scatter(\"time\",\"target\", data = plot_df[-60:], linewidth = 1)\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# # link: \"https://github.com/AsterLaoWhy/Thinkful/blob/master/1%20day%20target.png\"\n",
        "# plt.figure(figsize=(12,6))\n",
        "# plt.scatter(\"time\",\"target\", data = plot_df[-1440:], linewidth = 1)\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAGrU3FTQjyR",
        "colab_type": "text"
      },
      "source": [
        "Link to day:\n",
        "\n",
        "Link to hour:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jSk97j54WRj",
        "colab_type": "text"
      },
      "source": [
        "# At this point, things I can tune are\n",
        " - the time window of data being taken into the model\n",
        " - Which moving average the Bollinger bands are taking into account\n",
        " - Predicing the 4 moving average split rather than future price crosses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za6eAr1m5tj6",
        "colab_type": "text"
      },
      "source": [
        "### Let's run some classification supervised learning models to see how it works. I will try LogRegression, gradient boosted classification, neural nets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGG8UowSljzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaler = MinMaxScaler()\n",
        "# x = df.drop(['returns', 'target'], axis = 1)\n",
        "# y = df['target']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = .2, random_state = 69, shuffle = False)\n",
        "# X_train= scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "# y_test.to_csv('/content/drive/My Drive/Crypto/y_test.csv', index=False)  \n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/X_test.txt\",X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB6XYRpFS-sT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "dd45227d-865a-4d99-f8d0-86623441d412"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['open', 'close', 'high', 'low', 'volume', 'High 8 RMA', 'High 13 RMA',\n",
              "       'High 21 RMA', 'High 55 RMA', 'Bollinger High', 'Bollinger Low',\n",
              "       'returns', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu0cljt0idUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Due to Ram constraints, please see my second notebook for model comparison\n",
        "\n",
        "# LGR = LogisticRegression(class_weight = 'balanced', random_state = 69)\n",
        "# LGR.fit(X_train, y_train)\n",
        "# predictions = LGR.predict(X_test)\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/LGR_predictions.txt\", predictions)\n",
        "# pickle.dump(LGR, open(\"/content/drive/My Drive/Crypto/CryptoLGR_model.sav\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWw9Ut9aidZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Due to Ram constraints, please see my second notebook for model comparison\n",
        "# XGBC = XGBClassifier(max_depth = 2, learning_rate=.5, random_state=69)\n",
        "# XGBC.fit(X_train, y_train)\n",
        "# predictions = XGBC.predict(X_test)\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/XGB_predictions.txt\", predictions)\n",
        "# pickle.dump(XGBC, open(\"/content/drive/My Drive/Crypto/XGBC_model.sav\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OV2WRJqi0Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_df = df[df.columns.drop(list(df.filter(regex='t-')))]\n",
        "# lstm_df.to_csv('/content/drive/My Drive/Crypto/lstm_df.csv', index=False)\n",
        "X_train, y_train = convert_data(lstm_df[:788400].values, 60)\n",
        "X_test, y_test = convert_data(lstm_df[788401:].values, 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjtheMT9LJMv",
        "colab_type": "text"
      },
      "source": [
        "Here is the LSTM model. Uncomment the code to run it. Running this kills my kernal if I run any other model/unsupervised learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6UrK_8iC5Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #LSTM network\n",
        "# #for LSTM start , input_shape=(X_train.shape[1], X_train.shape[2]\n",
        "# # Answer below:\n",
        "# model = Sequential()\n",
        "# #Throw in some LSTM\n",
        "# model.add(LSTM(100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(75))\n",
        "# model.add(Dropout(0.2))\n",
        "# #Finish out the model\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "# model.add(Dense(1, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lVMMFZHZzck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Adam Spannbauer coming back as an optimizer\n",
        "# # I legit run out of ram after epoch 3 so I'm only doing 2 for that reason. Something to improve would be to have a better computer so I don't max out on ram\n",
        "# #But the metrics are all \"102s 39ms/step - loss: 7.5652 - accuracy: 0.5039 - val_loss: 7.4533 - val_accuracy: 0.5112\"\n",
        "# model.compile(optimizer = \"adam\", loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=300, epochs = 2)\n",
        "\n",
        "# model.save(\"/content/drive/My Drive/Crypto/lstm_model.h5\")\n",
        "# model.save_weights(\"/content/drive/My Drive/Crypto/lstm_model_weights.h5\")\n",
        "# predictions = model.predict(X_test)\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/LSTM_X.txt\", predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljUKW3W5aOKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now let's jump over to the other notebook for supervised learning/LSTM model comparisons..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD_MnW8M4FRi",
        "colab_type": "text"
      },
      "source": [
        "# Man, neural nets are performing bad. It's not that my features are bad, I don't ever blame myself... \"All this hype about neural nets for nothing\"- Jakob Salomonsson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBUqcRRvDlk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = df.drop(['returns', 'target'], axis = 1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = .2, random_state = 69, shuffle = False)\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_OWYD1bJtH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Maybe some unsupervised learning will help these models go super sayian\n",
        "#Let's try PCA and UMAP\n",
        "#For the PCA, I'm taking in already split data . I could take in the whole df minus target to fit PCA and then split. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDbNT5IY5iLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtY0mnOLRwbv",
        "colab_type": "text"
      },
      "source": [
        "Here I use the PCAed features to try to predict the stock movement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj1Hkz2NEx_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Trying 2,3,4 features. Want to see if this feature reduction will help the models will go further beyond\n",
        "# #2 components LGR\n",
        "# LGR = LogisticRegression(class_weight = 'balanced', random_state = 69)\n",
        "# pca = PCA(n_components=2)\n",
        "# PCA2_train = pca.fit_transform(X_train)\n",
        "# PCA2_test = pca.fit_transform(X_test)\n",
        "# LGR.fit(PCA2_train, y_train)\n",
        "# predictions = LGR.predict(PCA2_test)\n",
        "# pickle.dump(LGR, open(\"/content/drive/My Drive/Crypto/CryptoLGR2_model.sav\", \"wb\"))\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/LGR2_X.txt\",predictions)\n",
        "\n",
        "# #2 Component XGBC\n",
        "# XGBC = XGBClassifier(max_depth = 2, learning_rate=.5, random_state=69)\n",
        "# XGBC.fit(PCA2_train, y_train)\n",
        "# predictions = XGBC.predict(PCA2_test)\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/XGB2_predictions.txt\", predictions)\n",
        "# pickle.dump(XGBC, open(\"/content/drive/My Drive/Crypto/XGBC2_model.sav\", \"wb\"))\n",
        "\n",
        "\n",
        "# #---------------------------------------------------\n",
        "\n",
        "\n",
        "# #3 components\n",
        "# LGR = LogisticRegression(class_weight = 'balanced', random_state = 69)\n",
        "# pca = PCA(n_components=3)\n",
        "# PCA3_train = pca.fit_transform(X_train)\n",
        "# PCA3_test = pca.fit_transform(X_test)\n",
        "# LGR.fit(PCA3_train, y_train)\n",
        "# predictions = LGR.predict(PCA3_test)\n",
        "# pickle.dump(LGR, open(\"/content/drive/My Drive/Crypto/CryptoLGR3_model.sav\", \"wb\"))\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/LGR3_X.txt\",predictions)\n",
        "\n",
        "# # 3 component XGBC\n",
        "# XGBC = XGBClassifier(max_depth = 2, learning_rate=.5, random_state=69)\n",
        "# XGBC.fit(PCA3_train, y_train)\n",
        "# predictions = XGBC.predict(PCA3_test)\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/XGB3_predictions.txt\", predictions)\n",
        "# pickle.dump(XGBC, open(\"/content/drive/My Drive/Crypto/XGBC3_model.sav\", \"wb\"))\n",
        "\n",
        "\n",
        "# #-----------------------------------------------------\n",
        "\n",
        "\n",
        "# #4 components\n",
        "# LGR = LogisticRegression(class_weight = 'balanced', random_state = 69)\n",
        "# pca = PCA(n_components=4)\n",
        "# PCA4_train = pca.fit_transform(X_train)\n",
        "# PCA4_test = pca.fit_transform(X_test)\n",
        "# LGR.fit(PCA4_train, y_train)\n",
        "# predictions = LGR.predict(PCA4_test)\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/LGR4_X.txt\",predictions)\n",
        "# pickle.dump(LGR, open(\"/content/drive/My Drive/Crypto/CryptoLGR4_model.sav\", \"wb\"))\n",
        "# #4 components XGBC\n",
        "# XGBC = XGBClassifier(max_depth = 2, learning_rate=.5, random_state=69)\n",
        "# XGBC.fit(PCA4_train, y_train)\n",
        "# predictions = XGBC.predict(PCA4_test)\n",
        "# np.savetxt(\"/content/drive/My Drive/Crypto/XGB4_predictions.txt\", predictions)\n",
        "# pickle.dump(XGBC, open(\"/content/drive/My Drive/Crypto/XGBC4_model.sav\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVkpdDlsDGq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This takes over 2 hours. I'm not going to do it now. Maybe if I upgrade my computer, I'll do it\n",
        "#This is why I'm only doing 1\n",
        "import time\n",
        "time_start = time.time()\n",
        "UX_train = umap.UMAP(n_neighbors=3, min_dist=0.5, metric='correlation').fit_transform(X_train)\n",
        "UX_test = umap.UMAP(n_neighbors=3, min_dist=0.5, metric='correlation').fit_transform(X_test)\n",
        "#umap is taking forever so I'm just going to do one iteration of it. 3 \n",
        "print('UMAP done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzgTFBCeNcbg",
        "colab_type": "text"
      },
      "source": [
        "# Final conclusions\n",
        "\n",
        "\n",
        "Hypothesis: Rejection! I don't make money. \n",
        "\n",
        "# WHY?\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# THIS IS MY METRIC! HOW MUCH MONEY WAS MADE IN A WEEK\n",
        "\n",
        "while precision (% correctly predicted buy) recall(%buy predicted over total buy) accuracy, and F1 (mean of precision and recall) are important, investors don'care more about how much money the model makes. Therefore, I am focusing in on amount made as the main metric. The other metrics can be used to better understand and tune models, but for investors, they just want to know how much money the models will make them.\n",
        "\n",
        "---------------------------------------------------------------------\n",
        "\n",
        "If I invested $1000, how much would I end up with in a week?\n",
        "\n",
        "If prediction was 100% correct: $1070.95\n",
        "\n",
        "Logistic Regression: $982.93\n",
        "\n",
        "So I would lose money if I were to follow any of my models. Therefore, I reject the hypothesis\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "creativity in features = lack of earned money. The feature reduction methods don't even perfom better than the base signal.\n",
        "- The simple up/down prediction loses around 1% per day\n",
        "- The Bollinger band strategy also loses X% per day\n",
        "- The youtube guru strategy loses money at x% per day\n",
        "\n",
        "The top two strategies were things that I thought of. The final strategy is linked below\n",
        "\n",
        "guru strategy = \"https://www.youtube.com/watch?v=mqqx4cGyUoY \"\n",
        "\n",
        "\n",
        "There is a bunch of room for improvement (obviously) but that's for another day\n"
      ]
    }
  ]
}